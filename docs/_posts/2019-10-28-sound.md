---
layout: post
title: "Sound"
categories: notes
---

Almost all the material we've covered so far has dealt with computer vision. The following notes deal with another important "sense", sound.

openFrameworks might not seem like the obvious choice for manipulating sound. Part of the issue is that development of the sound modules in OF have been stop-and-go since the beginning; especially compared to other tools like [Max](https://cycling74.com/) which place audio front and center, and have a more visual approach to working with sound data and devices. That being said, sound analysis and manipulation is still quite developed in OF and involves some interesting concepts that should be explored.

### Sound Stream

The primary object for working with sound is [`ofSoundStream`](https://openframeworks.cc/documentation/sound/ofSoundStream/). An `ofSoundStream` controls access to the computer's audio input and output devices, and allows the manipulation of the sound data in real-time. 

Typical apps will only use a single sound stream, and openFrameworks gives you easy access to a default `ofSoundStream` using `ofSoundStreamXXX()` global functions like [`ofSoundStreamSetup()`](https://openframeworks.cc/documentation/sound/ofSoundStream/#show_ofSoundStreamSetup) or [`ofSoundStreamClose()`](https://openframeworks.cc/documentation/sound/ofSoundStream/#show_ofSoundStreamClose). However, we like to be explicit in this class so our examples will always create our own `ofSoundStream` object :)

An `ofSoundStream` is set up with an [`ofSoundStreamSettings`](https://openframeworks.cc/documentation/sound/ofSoundStreamSettings/). This sets the sound hardware to use, the buffer properties like number of channels and sample rate, the callbacks for reading and writing sound data, etc.

```cpp
ofSoundStreamSettings settings;
settings.sampleRate = 44100;
settings.bufferSize = 256;
settings.numOutputChannels = 2;
settings.numInputChannels = 0;

soundStream.setup(settings);
```

We can list the installed sound devices on our system using [`ofSoundStream.printDeviceList()`](https://openframeworks.cc/documentation/sound/ofSoundStream/#show_printDeviceList). This will print all the information out to the console, including the interface used and the number of available input and output channels per device.

This will look something like:
```
[notice ] ofBaseSoundStream::printDeviceList: Api: MS WASAPI
[notice ] ofBaseSoundStream::printDeviceList: [MS WASAPI: 0] DELL U2713HM (NVIDIA High Definition Audio) [in:0 out:2]
[MS WASAPI: 1] Speakers (Realtek High Definition Audio) [in:0 out:2] (default out)
[MS WASAPI: 2] Realtek Digital Output(Optical) (Realtek High Definition Audio) [in:0 out:2]
[MS WASAPI: 3] Realtek Digital Output (Realtek High Definition Audio) [in:0 out:2]
[MS WASAPI: 4] Microphone (HD Pro Webcam C920) [in:2 out:0]
[MS WASAPI: 5] Microphone Array (Xbox NUI Sensor) [in:4 out:0] (default in)
```

### Sound Buffer

Sound data is packed into an [`ofSoundBuffer`](https://openframeworks.cc/documentation/sound/ofSoundBuffer/).

As the name implies, `ofSoundBuffer` includes the sound buffer data. 
* Buffer values are `float`, with range from `-1` to `1`. Think of this as a waveform, with `0` at the origin.
* This can be used like an array, using the [`[]`](https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_operator%5B%5D) operator and an index to access each element.
* Just like an `ofPixels` array, the sound data is *interleaved* in the buffer. This means that if we have 2 channels of audio, it will be packed as `LRLRLRLRLR...`.
* [`size()`](https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_size) returns the total buffer size.
* [`getNumChannels()`](https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_getNumChannels) returns the number of channels.
* [`getNumFrames()`](https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_getNumFrames) returns the number of frames, which is the buffer size per channel. This is essentially the size divided by the number of channels.

`ofSoundBuffer` also includes a few other getters and setters:
* Some to interface with the audio hardware, like [`getDeviceID()`](https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_getDeviceID) and [`setSampleRate()`](https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_setSampleRate).
* Some to manipulate the signal, like [`fillWithNoise()`](https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_fillWithNoise) and [`resample()`](https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_resample).

### Sound Input

To receive audio in OF, we need to:
* Set the input channels of our `ofSoundStream` to a value greater than `0`. 
* Set an audio listener to the `ofSoundStream` using [`ofSoundStreamSettings.setInListener()`](https://openframeworks.cc/documentation/sound/ofSoundStreamSettings/#show_setInListener). This can be any class that extends from `ofBaseSoundInput`, which includes our `ofApp`.
* Implement the [`audioIn()`](https://openframeworks.cc/documentation/types/ofBaseSoundInput/#show_audioIn) function in our listener class.

{% gist bf8bab6eea766d4c42ef1a39120e2c81 ofApp-input.h %} 
{% gist bf8bab6eea766d4c42ef1a39120e2c81 ofApp-input.cpp %}

#### RMS

To calculate audio levels, we need to consider all samples in the received buffer. We could try adding and averaging all values in our buffer, but since the values oscillate between `-1` and `1`, we would probably always end up with something near `0` (since the negatives will cancel out the positives). A good way to approximate the audio level is to calculate the root mean square (RMS), which ensures that the samples collected are always positive.

{% gist bf8bab6eea766d4c42ef1a39120e2c81 ofApp-inRms.h %} 
{% gist bf8bab6eea766d4c42ef1a39120e2c81 ofApp-inRms.cpp %}

In the above example, note that:
* The RMS value is very volatile, so we smooth it out using `ofLerp()`.
* The RMS value does not necessarily go up to `1.0` at it's peak, so we scale it up using `ofMap()` and its peak recorded value. 
* Buffer samples sometimes go out of range. I'm not sure why but I think it occurs when no data is present, and only on specific hardware. This needs to be cleaned up before making any calculations, so we adjust outlier values using `ofClamp()`.

If we draw a graph of what our raw samples look like, we can indeed see that the tail end values seem to shoot up.

{% gist bf8bab6eea766d4c42ef1a39120e2c81 ofApp-inGraph.h %} 
{% gist bf8bab6eea766d4c42ef1a39120e2c81 ofApp-inGraph.cpp %}

![]({{ site.baseurl }}/assets/images/sound-graph.png){:width="600px"}

#### Onset Detection

We can use the RMS for onset or beat detection. We can set a threshold value and every time the RMS goes above it, a new beat is recorded. We can then use this to have an action happen to the tempo of the audio.

{% gist bf8bab6eea766d4c42ef1a39120e2c81 ofApp-inOnset.h %} 
{% gist bf8bab6eea766d4c42ef1a39120e2c81 ofApp-inOnset.cpp %}

#### FFT

Onset detection works fine when you have fairly isolated audio, like footsteps or a bass drum beat, but degenerates fairly quickly when the sound source becomes more complex and involves multiple frequencies.

The Fast Fourier Transform (FFT) is an algorithm used to take in a sound sample and compute the levels for an array of frequencies. This essentially splits up the audio into different bands that can be analyzed separately.

FFT does not work out of the box with OF sound input, so we will need to use the [ofxFft](https://github.com/kylemcdonald/ofxFft) addon. This addon includes a few examples to get going as well as two different FFT implementations, but we'll just use the default for this example.

{% gist bf8bab6eea766d4c42ef1a39120e2c81 ofApp-inFft.h %} 
{% gist bf8bab6eea766d4c42ef1a39120e2c81 ofApp-inFft.cpp %}

![]({{ site.baseurl }}/assets/images/sound-fft.png){:width="600px"}

### Sound Player

[`ofSoundPlayer`](https://openframeworks.cc///documentation/sound/ofSoundPlayer/) is used to play sound files. The OF examples do a good job of showing all the functionality here, so I won't spend time on it now.

### Sound Synthesis

Generating sound in OF also starts with an `ofSoundStream`:
* Set the output channels of our `ofSoundStream` to a value greater than `0`. 
* Set an audio listener to the `ofSoundStream` using [`ofSoundStreamSettings.setOutListener()`](https://openframeworks.cc/documentation/sound/ofSoundStreamSettings/#show_setOutListener). This can be any class that extends from `ofBaseSoundOutput`, which includes our `ofApp`.
* Implement the [`audioOut()`](https://openframeworks.cc/documentation/types/ofBaseSoundOutput/#!show_audioOut) function in our listener class.

{% gist 350c1d31315fb84c6024a938c190acc7 ofApp-output.h %} 
{% gist 350c1d31315fb84c6024a938c190acc7 ofApp-output.cpp %}

#### Signal Generator

We need to fill the buffer received in `audioOut()` with data to produce sound.
* We will generate a sine wave and send it to both left and right channels.
* The pan (balance between left and right channels) will be updated using the mouse x position.
* The phase (length of sine wave period) will be updated using the mouse y position. The shorter the phase, the higher the sound frequency.
* We want the sine wave to be continuous, so we'll use a class variable `phaseVal` to keep track of the value across frames.
* We want to avoid any jumps in phase values because these might lead to "pops" in the sound, so `phaseStep` will change gradually using `ofLerp()`.

{% gist 350c1d31315fb84c6024a938c190acc7 ofApp-outSin.h %} 
{% gist 350c1d31315fb84c6024a938c190acc7 ofApp-outSin.cpp %}

![]({{ site.baseurl }}/assets/images/sound-sin.png){:width="600px"}

#### Noise Generator

We can generate signal from a variety of sources. Using [Perlin noise](https://en.wikipedia.org/wiki/Perlin_noise) leads to interesting results, because it offers a good balance between randomness and continuity. In OF, we can use [`ofSignedNoise()`](https://openframeworks.cc/documentation/math/ofMath/#show_ofSignedNoise) because it returns values in the same domain that our buffer expects, from `-1` to `1`. 

{% gist 350c1d31315fb84c6024a938c190acc7 ofApp-outNoise.h %} 
{% gist 350c1d31315fb84c6024a938c190acc7 ofApp-outNoise.cpp %}

![]({{ site.baseurl }}/assets/images/sound-noise.png){:width="600px"}

### MIDI

MIDI (which stands for Musical Instrument Digital Interface) is a communication protocol that is a standard for audio messages. MIDI has been around since the 1980s and is pretty universal; if you have any piece of hardware or software that is used for music, there is a good chance it supports MIDI.

The MIDI specification consists of different types of messages, including:
* *Note On* and *Note Off* to trigger notes.
* *Polyphonic Key Pressure* and *Pitch Bend* to affect the played notes.
* *Control Change* and *Program Change* to set mode and functionality.
* *System* to control playback and device specific features.

In OF, we can use [`ofxMidi`](https://github.com/danomatika/ofxMidi) for input and output.

The following example uses a controller to trigger notes in OF.
* `ofApp` extends `ofxMidiListener` (on top of `ofBaseApp`) to get access to the MIDI listeners.
* `ofApp` implements the `newMidiMessage()` function to handle incoming messages.
* All possible frequencies are calculated at startup and stored in a look-up table.
* The target frequency is set whenever a MIDI note message is received. 

{% gist 350c1d31315fb84c6024a938c190acc7 ofApp-outMidi.h %} 
{% gist 350c1d31315fb84c6024a938c190acc7 ofApp-outMidi.cpp %}

### Sound Addons

There are a few other sound addons available to explore. Some recommendations:

* [ofxSoundObjects](https://github.com/roymacdonald/ofxSoundObjects) uses the idea of *sound objects* as components that audio moves through. Each has an input and output, so they can be connected to one another to stack sounds and filters.
* [ofxTonic](https://github.com/TonicAudio/ofxTonic) is an OF wrapper for [Tonic](https://github.com/TonicAudio/Tonic), a high performance C++ audio synthesis library. It works on top of the OF sound engine and makes sound generation fun and easy.
